# NLP基础

## Metrics
* Perplexity: it quantifies how well the model predicts the next word in a sequence. Lower perplexity indicates that the model is more confident and better at predicting the text. Commonly used in evaluating the performance of language models during training.
* BLEU compares the generated text (candidate) to one or more reference texts (human translations) by measuring the overlap of n-grams. BLEU scores range from 0 to 1, where a higher score indicates better quality. BLEU is primarily used in machine translation evaluation, assessing how closely machine-generated text matches human translations.